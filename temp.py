# File: extract_first_argument.py

# Replace this with your code as a multi-line string or read from a file
code = """

pub const INSTRUCTIONS: [(&str, u32, &[(&str, usize)]); 411] = [
    ("vaadd.vv", MATCH_VAADD_VV, ARGS_VAADD_VV),
    ("vaadd.vx", MATCH_VAADD_VX, ARGS_VAADD_VX),
    ("vaaddu.vv", MATCH_VAADDU_VV, ARGS_VAADDU_VV),
    ("vaaddu.vx", MATCH_VAADDU_VX, ARGS_VAADDU_VX),
    ("vadc.vim", MATCH_VADC_VIM, ARGS_VADC_VIM),
    ("vadc.vvm", MATCH_VADC_VVM, ARGS_VADC_VVM),
    ("vadc.vxm", MATCH_VADC_VXM, ARGS_VADC_VXM),
    ("vadd.vi", MATCH_VADD_VI, ARGS_VADD_VI),
    ("vadd.vv", MATCH_VADD_VV, ARGS_VADD_VV),
    ("vadd.vx", MATCH_VADD_VX, ARGS_VADD_VX),
    ("vand.vi", MATCH_VAND_VI, ARGS_VAND_VI),
    ("vand.vv", MATCH_VAND_VV, ARGS_VAND_VV),
    ("vand.vx", MATCH_VAND_VX, ARGS_VAND_VX),
    ("vasub.vv", MATCH_VASUB_VV, ARGS_VASUB_VV),
    ("vasub.vx", MATCH_VASUB_VX, ARGS_VASUB_VX),
    ("vasubu.vv", MATCH_VASUBU_VV, ARGS_VASUBU_VV),
    ("vasubu.vx", MATCH_VASUBU_VX, ARGS_VASUBU_VX),
    ("vcompress.vm", MATCH_VCOMPRESS_VM, ARGS_VCOMPRESS_VM),
    ("vcpop.m", MATCH_VCPOP_M, ARGS_VCPOP_M),
    ("vdiv.vv", MATCH_VDIV_VV, ARGS_VDIV_VV),
    ("vdiv.vx", MATCH_VDIV_VX, ARGS_VDIV_VX),
    ("vdivu.vv", MATCH_VDIVU_VV, ARGS_VDIVU_VV),
    ("vdivu.vx", MATCH_VDIVU_VX, ARGS_VDIVU_VX),
    ("vfadd.vf", MATCH_VFADD_VF, ARGS_VFADD_VF),
    ("vfadd.vv", MATCH_VFADD_VV, ARGS_VFADD_VV),
    ("vfclass.v", MATCH_VFCLASS_V, ARGS_VFCLASS_V),
    ("vfcvt.f.x.v", MATCH_VFCVT_F_X_V, ARGS_VFCVT_F_X_V),
    ("vfcvt.f.xu.v", MATCH_VFCVT_F_XU_V, ARGS_VFCVT_F_XU_V),
    (
        "vfcvt.rtz.x.f.v",
        MATCH_VFCVT_RTZ_X_F_V,
        ARGS_VFCVT_RTZ_X_F_V,
    ),
    (
        "vfcvt.rtz.xu.f.v",
        MATCH_VFCVT_RTZ_XU_F_V,
        ARGS_VFCVT_RTZ_XU_F_V,
    ),
    ("vfcvt.x.f.v", MATCH_VFCVT_X_F_V, ARGS_VFCVT_X_F_V),
    ("vfcvt.xu.f.v", MATCH_VFCVT_XU_F_V, ARGS_VFCVT_XU_F_V),
    ("vfdiv.vf", MATCH_VFDIV_VF, ARGS_VFDIV_VF),
    ("vfdiv.vv", MATCH_VFDIV_VV, ARGS_VFDIV_VV),
    ("vfirst.m", MATCH_VFIRST_M, ARGS_VFIRST_M),
    ("vfmacc.vf", MATCH_VFMACC_VF, ARGS_VFMACC_VF),
    ("vfmacc.vv", MATCH_VFMACC_VV, ARGS_VFMACC_VV),
    ("vfmadd.vf", MATCH_VFMADD_VF, ARGS_VFMADD_VF),
    ("vfmadd.vv", MATCH_VFMADD_VV, ARGS_VFMADD_VV),
    ("vfmax.vf", MATCH_VFMAX_VF, ARGS_VFMAX_VF),
    ("vfmax.vv", MATCH_VFMAX_VV, ARGS_VFMAX_VV),
    ("vfmerge.vfm", MATCH_VFMERGE_VFM, ARGS_VFMERGE_VFM),
    ("vfmin.vf", MATCH_VFMIN_VF, ARGS_VFMIN_VF),
    ("vfmin.vv", MATCH_VFMIN_VV, ARGS_VFMIN_VV),
    ("vfmsac.vf", MATCH_VFMSAC_VF, ARGS_VFMSAC_VF),
    ("vfmsac.vv", MATCH_VFMSAC_VV, ARGS_VFMSAC_VV),
    ("vfmsub.vf", MATCH_VFMSUB_VF, ARGS_VFMSUB_VF),
    ("vfmsub.vv", MATCH_VFMSUB_VV, ARGS_VFMSUB_VV),
    ("vfmul.vf", MATCH_VFMUL_VF, ARGS_VFMUL_VF),
    ("vfmul.vv", MATCH_VFMUL_VV, ARGS_VFMUL_VV),
    ("vfmv.f.s", MATCH_VFMV_F_S, ARGS_VFMV_F_S),
    ("vfmv.s.f", MATCH_VFMV_S_F, ARGS_VFMV_S_F),
    ("vfmv.v.f", MATCH_VFMV_V_F, ARGS_VFMV_V_F),
    ("vfncvt.f.f.w", MATCH_VFNCVT_F_F_W, ARGS_VFNCVT_F_F_W),
    ("vfncvt.f.x.w", MATCH_VFNCVT_F_X_W, ARGS_VFNCVT_F_X_W),
    ("vfncvt.f.xu.w", MATCH_VFNCVT_F_XU_W, ARGS_VFNCVT_F_XU_W),
    (
        "vfncvt.rod.f.f.w",
        MATCH_VFNCVT_ROD_F_F_W,
        ARGS_VFNCVT_ROD_F_F_W,
    ),
    (
        "vfncvt.rtz.x.f.w",
        MATCH_VFNCVT_RTZ_X_F_W,
        ARGS_VFNCVT_RTZ_X_F_W,
    ),
    (
        "vfncvt.rtz.xu.f.w",
        MATCH_VFNCVT_RTZ_XU_F_W,
        ARGS_VFNCVT_RTZ_XU_F_W,
    ),
    ("vfncvt.x.f.w", MATCH_VFNCVT_X_F_W, ARGS_VFNCVT_X_F_W),
    ("vfncvt.xu.f.w", MATCH_VFNCVT_XU_F_W, ARGS_VFNCVT_XU_F_W),
    ("vfnmacc.vf", MATCH_VFNMACC_VF, ARGS_VFNMACC_VF),
    ("vfnmacc.vv", MATCH_VFNMACC_VV, ARGS_VFNMACC_VV),
    ("vfnmadd.vf", MATCH_VFNMADD_VF, ARGS_VFNMADD_VF),
    ("vfnmadd.vv", MATCH_VFNMADD_VV, ARGS_VFNMADD_VV),
    ("vfnmsac.vf", MATCH_VFNMSAC_VF, ARGS_VFNMSAC_VF),
    ("vfnmsac.vv", MATCH_VFNMSAC_VV, ARGS_VFNMSAC_VV),
    ("vfnmsub.vf", MATCH_VFNMSUB_VF, ARGS_VFNMSUB_VF),
    ("vfnmsub.vv", MATCH_VFNMSUB_VV, ARGS_VFNMSUB_VV),
    ("vfrdiv.vf", MATCH_VFRDIV_VF, ARGS_VFRDIV_VF),
    ("vfrec7.v", MATCH_VFREC7_V, ARGS_VFREC7_V),
    ("vfredmax.vs", MATCH_VFREDMAX_VS, ARGS_VFREDMAX_VS),
    ("vfredmin.vs", MATCH_VFREDMIN_VS, ARGS_VFREDMIN_VS),
    ("vfredosum.vs", MATCH_VFREDOSUM_VS, ARGS_VFREDOSUM_VS),
    ("vfredusum.vs", MATCH_VFREDUSUM_VS, ARGS_VFREDUSUM_VS),
    ("vfrsqrt7.v", MATCH_VFRSQRT7_V, ARGS_VFRSQRT7_V),
    ("vfrsub.vf", MATCH_VFRSUB_VF, ARGS_VFRSUB_VF),
    ("vfsgnj.vf", MATCH_VFSGNJ_VF, ARGS_VFSGNJ_VF),
    ("vfsgnj.vv", MATCH_VFSGNJ_VV, ARGS_VFSGNJ_VV),
    ("vfsgnjn.vf", MATCH_VFSGNJN_VF, ARGS_VFSGNJN_VF),
    ("vfsgnjn.vv", MATCH_VFSGNJN_VV, ARGS_VFSGNJN_VV),
    ("vfsgnjx.vf", MATCH_VFSGNJX_VF, ARGS_VFSGNJX_VF),
    ("vfsgnjx.vv", MATCH_VFSGNJX_VV, ARGS_VFSGNJX_VV),
    (
        "vfslide1down.vf",
        MATCH_VFSLIDE1DOWN_VF,
        ARGS_VFSLIDE1DOWN_VF,
    ),
    ("vfslide1up.vf", MATCH_VFSLIDE1UP_VF, ARGS_VFSLIDE1UP_VF),
    ("vfsqrt.v", MATCH_VFSQRT_V, ARGS_VFSQRT_V),
    ("vfsub.vf", MATCH_VFSUB_VF, ARGS_VFSUB_VF),
    ("vfsub.vv", MATCH_VFSUB_VV, ARGS_VFSUB_VV),
    ("vfwadd.vf", MATCH_VFWADD_VF, ARGS_VFWADD_VF),
    ("vfwadd.vv", MATCH_VFWADD_VV, ARGS_VFWADD_VV),
    ("vfwadd.wf", MATCH_VFWADD_WF, ARGS_VFWADD_WF),
    ("vfwadd.wv", MATCH_VFWADD_WV, ARGS_VFWADD_WV),
    ("vfwcvt.f.f.v", MATCH_VFWCVT_F_F_V, ARGS_VFWCVT_F_F_V),
    ("vfwcvt.f.x.v", MATCH_VFWCVT_F_X_V, ARGS_VFWCVT_F_X_V),
    ("vfwcvt.f.xu.v", MATCH_VFWCVT_F_XU_V, ARGS_VFWCVT_F_XU_V),
    (
        "vfwcvt.rtz.x.f.v",
        MATCH_VFWCVT_RTZ_X_F_V,
        ARGS_VFWCVT_RTZ_X_F_V,
    ),
    (
        "vfwcvt.rtz.xu.f.v",
        MATCH_VFWCVT_RTZ_XU_F_V,
        ARGS_VFWCVT_RTZ_XU_F_V,
    ),
    ("vfwcvt.x.f.v", MATCH_VFWCVT_X_F_V, ARGS_VFWCVT_X_F_V),
    ("vfwcvt.xu.f.v", MATCH_VFWCVT_XU_F_V, ARGS_VFWCVT_XU_F_V),
    ("vfwmacc.vf", MATCH_VFWMACC_VF, ARGS_VFWMACC_VF),
    ("vfwmacc.vv", MATCH_VFWMACC_VV, ARGS_VFWMACC_VV),
    ("vfwmsac.vf", MATCH_VFWMSAC_VF, ARGS_VFWMSAC_VF),
    ("vfwmsac.vv", MATCH_VFWMSAC_VV, ARGS_VFWMSAC_VV),
    ("vfwmul.vf", MATCH_VFWMUL_VF, ARGS_VFWMUL_VF),
    ("vfwmul.vv", MATCH_VFWMUL_VV, ARGS_VFWMUL_VV),
    ("vfwnmacc.vf", MATCH_VFWNMACC_VF, ARGS_VFWNMACC_VF),
    ("vfwnmacc.vv", MATCH_VFWNMACC_VV, ARGS_VFWNMACC_VV),
    ("vfwnmsac.vf", MATCH_VFWNMSAC_VF, ARGS_VFWNMSAC_VF),
    ("vfwnmsac.vv", MATCH_VFWNMSAC_VV, ARGS_VFWNMSAC_VV),
    ("vfwredosum.vs", MATCH_VFWREDOSUM_VS, ARGS_VFWREDOSUM_VS),
    ("vfwredusum.vs", MATCH_VFWREDUSUM_VS, ARGS_VFWREDUSUM_VS),
    ("vfwsub.vf", MATCH_VFWSUB_VF, ARGS_VFWSUB_VF),
    ("vfwsub.vv", MATCH_VFWSUB_VV, ARGS_VFWSUB_VV),
    ("vfwsub.wf", MATCH_VFWSUB_WF, ARGS_VFWSUB_WF),
    ("vfwsub.wv", MATCH_VFWSUB_WV, ARGS_VFWSUB_WV),
    ("vid.v", MATCH_VID_V, ARGS_VID_V),
    ("viota.m", MATCH_VIOTA_M, ARGS_VIOTA_M),
    ("vl1re16.v", MATCH_VL1RE16_V, ARGS_VL1RE16_V),
    ("vl1re32.v", MATCH_VL1RE32_V, ARGS_VL1RE32_V),
    ("vl1re64.v", MATCH_VL1RE64_V, ARGS_VL1RE64_V),
    ("vl1re8.v", MATCH_VL1RE8_V, ARGS_VL1RE8_V),
    ("vl2re16.v", MATCH_VL2RE16_V, ARGS_VL2RE16_V),
    ("vl2re32.v", MATCH_VL2RE32_V, ARGS_VL2RE32_V),
    ("vl2re64.v", MATCH_VL2RE64_V, ARGS_VL2RE64_V),
    ("vl2re8.v", MATCH_VL2RE8_V, ARGS_VL2RE8_V),
    ("vl4re16.v", MATCH_VL4RE16_V, ARGS_VL4RE16_V),
    ("vl4re32.v", MATCH_VL4RE32_V, ARGS_VL4RE32_V),
    ("vl4re64.v", MATCH_VL4RE64_V, ARGS_VL4RE64_V),
    ("vl4re8.v", MATCH_VL4RE8_V, ARGS_VL4RE8_V),
    ("vl8re16.v", MATCH_VL8RE16_V, ARGS_VL8RE16_V),
    ("vl8re32.v", MATCH_VL8RE32_V, ARGS_VL8RE32_V),
    ("vl8re64.v", MATCH_VL8RE64_V, ARGS_VL8RE64_V),
    ("vl8re8.v", MATCH_VL8RE8_V, ARGS_VL8RE8_V),
    ("vle1024.v", MATCH_VLE1024_V, ARGS_VLE1024_V),
    ("vle1024ff.v", MATCH_VLE1024FF_V, ARGS_VLE1024FF_V),
    ("vle128.v", MATCH_VLE128_V, ARGS_VLE128_V),
    ("vle128ff.v", MATCH_VLE128FF_V, ARGS_VLE128FF_V),
    ("vle16.v", MATCH_VLE16_V, ARGS_VLE16_V),
    ("vle16ff.v", MATCH_VLE16FF_V, ARGS_VLE16FF_V),
    ("vle256.v", MATCH_VLE256_V, ARGS_VLE256_V),
    ("vle256ff.v", MATCH_VLE256FF_V, ARGS_VLE256FF_V),
    ("vle32.v", MATCH_VLE32_V, ARGS_VLE32_V),
    ("vle32ff.v", MATCH_VLE32FF_V, ARGS_VLE32FF_V),
    ("vle512.v", MATCH_VLE512_V, ARGS_VLE512_V),
    ("vle512ff.v", MATCH_VLE512FF_V, ARGS_VLE512FF_V),
    ("vle64.v", MATCH_VLE64_V, ARGS_VLE64_V),
    ("vle64ff.v", MATCH_VLE64FF_V, ARGS_VLE64FF_V),
    ("vle8.v", MATCH_VLE8_V, ARGS_VLE8_V),
    ("vle8ff.v", MATCH_VLE8FF_V, ARGS_VLE8FF_V),
    ("vlm.v", MATCH_VLM_V, ARGS_VLM_V),
    ("vloxei1024.v", MATCH_VLOXEI1024_V, ARGS_VLOXEI1024_V),
    ("vloxei128.v", MATCH_VLOXEI128_V, ARGS_VLOXEI128_V),
    ("vloxei16.v", MATCH_VLOXEI16_V, ARGS_VLOXEI16_V),
    ("vloxei256.v", MATCH_VLOXEI256_V, ARGS_VLOXEI256_V),
    ("vloxei32.v", MATCH_VLOXEI32_V, ARGS_VLOXEI32_V),
    ("vloxei512.v", MATCH_VLOXEI512_V, ARGS_VLOXEI512_V),
    ("vloxei64.v", MATCH_VLOXEI64_V, ARGS_VLOXEI64_V),
    ("vloxei8.v", MATCH_VLOXEI8_V, ARGS_VLOXEI8_V),
    ("vlse1024.v", MATCH_VLSE1024_V, ARGS_VLSE1024_V),
    ("vlse128.v", MATCH_VLSE128_V, ARGS_VLSE128_V),
    ("vlse16.v", MATCH_VLSE16_V, ARGS_VLSE16_V),
    ("vlse256.v", MATCH_VLSE256_V, ARGS_VLSE256_V),
    ("vlse32.v", MATCH_VLSE32_V, ARGS_VLSE32_V),
    ("vlse512.v", MATCH_VLSE512_V, ARGS_VLSE512_V),
    ("vlse64.v", MATCH_VLSE64_V, ARGS_VLSE64_V),
    ("vlse8.v", MATCH_VLSE8_V, ARGS_VLSE8_V),
    ("vluxei1024.v", MATCH_VLUXEI1024_V, ARGS_VLUXEI1024_V),
    ("vluxei128.v", MATCH_VLUXEI128_V, ARGS_VLUXEI128_V),
    ("vluxei16.v", MATCH_VLUXEI16_V, ARGS_VLUXEI16_V),
    ("vluxei256.v", MATCH_VLUXEI256_V, ARGS_VLUXEI256_V),
    ("vluxei32.v", MATCH_VLUXEI32_V, ARGS_VLUXEI32_V),
    ("vluxei512.v", MATCH_VLUXEI512_V, ARGS_VLUXEI512_V),
    ("vluxei64.v", MATCH_VLUXEI64_V, ARGS_VLUXEI64_V),
    ("vluxei8.v", MATCH_VLUXEI8_V, ARGS_VLUXEI8_V),
    ("vmacc.vv", MATCH_VMACC_VV, ARGS_VMACC_VV),
    ("vmacc.vx", MATCH_VMACC_VX, ARGS_VMACC_VX),
    ("vmadc.vi", MATCH_VMADC_VI, ARGS_VMADC_VI),
    ("vmadc.vim", MATCH_VMADC_VIM, ARGS_VMADC_VIM),
    ("vmadc.vv", MATCH_VMADC_VV, ARGS_VMADC_VV),
    ("vmadc.vvm", MATCH_VMADC_VVM, ARGS_VMADC_VVM),
    ("vmadc.vx", MATCH_VMADC_VX, ARGS_VMADC_VX),
    ("vmadc.vxm", MATCH_VMADC_VXM, ARGS_VMADC_VXM),
    ("vmadd.vv", MATCH_VMADD_VV, ARGS_VMADD_VV),
    ("vmadd.vx", MATCH_VMADD_VX, ARGS_VMADD_VX),
    ("vmand.mm", MATCH_VMAND_MM, ARGS_VMAND_MM),
    ("vmandn.mm", MATCH_VMANDN_MM, ARGS_VMANDN_MM),
    ("vmax.vv", MATCH_VMAX_VV, ARGS_VMAX_VV),
    ("vmax.vx", MATCH_VMAX_VX, ARGS_VMAX_VX),
    ("vmaxu.vv", MATCH_VMAXU_VV, ARGS_VMAXU_VV),
    ("vmaxu.vx", MATCH_VMAXU_VX, ARGS_VMAXU_VX),
    ("vmerge.vim", MATCH_VMERGE_VIM, ARGS_VMERGE_VIM),
    ("vmerge.vvm", MATCH_VMERGE_VVM, ARGS_VMERGE_VVM),
    ("vmerge.vxm", MATCH_VMERGE_VXM, ARGS_VMERGE_VXM),
    ("vmfeq.vf", MATCH_VMFEQ_VF, ARGS_VMFEQ_VF),
    ("vmfeq.vv", MATCH_VMFEQ_VV, ARGS_VMFEQ_VV),
    ("vmfge.vf", MATCH_VMFGE_VF, ARGS_VMFGE_VF),
    ("vmfgt.vf", MATCH_VMFGT_VF, ARGS_VMFGT_VF),
    ("vmfle.vf", MATCH_VMFLE_VF, ARGS_VMFLE_VF),
    ("vmfle.vv", MATCH_VMFLE_VV, ARGS_VMFLE_VV),
    ("vmflt.vf", MATCH_VMFLT_VF, ARGS_VMFLT_VF),
    ("vmflt.vv", MATCH_VMFLT_VV, ARGS_VMFLT_VV),
    ("vmfne.vf", MATCH_VMFNE_VF, ARGS_VMFNE_VF),
    ("vmfne.vv", MATCH_VMFNE_VV, ARGS_VMFNE_VV),
    ("vmin.vv", MATCH_VMIN_VV, ARGS_VMIN_VV),
    ("vmin.vx", MATCH_VMIN_VX, ARGS_VMIN_VX),
    ("vminu.vv", MATCH_VMINU_VV, ARGS_VMINU_VV),
    ("vminu.vx", MATCH_VMINU_VX, ARGS_VMINU_VX),
    ("vmnand.mm", MATCH_VMNAND_MM, ARGS_VMNAND_MM),
    ("vmnor.mm", MATCH_VMNOR_MM, ARGS_VMNOR_MM),
    ("vmor.mm", MATCH_VMOR_MM, ARGS_VMOR_MM),
    ("vmorn.mm", MATCH_VMORN_MM, ARGS_VMORN_MM),
    ("vmsbc.vv", MATCH_VMSBC_VV, ARGS_VMSBC_VV),
    ("vmsbc.vvm", MATCH_VMSBC_VVM, ARGS_VMSBC_VVM),
    ("vmsbc.vx", MATCH_VMSBC_VX, ARGS_VMSBC_VX),
    ("vmsbc.vxm", MATCH_VMSBC_VXM, ARGS_VMSBC_VXM),
    ("vmsbf.m", MATCH_VMSBF_M, ARGS_VMSBF_M),
    ("vmseq.vi", MATCH_VMSEQ_VI, ARGS_VMSEQ_VI),
    ("vmseq.vv", MATCH_VMSEQ_VV, ARGS_VMSEQ_VV),
    ("vmseq.vx", MATCH_VMSEQ_VX, ARGS_VMSEQ_VX),
    ("vmsgt.vi", MATCH_VMSGT_VI, ARGS_VMSGT_VI),
    ("vmsgt.vx", MATCH_VMSGT_VX, ARGS_VMSGT_VX),
    ("vmsgtu.vi", MATCH_VMSGTU_VI, ARGS_VMSGTU_VI),
    ("vmsgtu.vx", MATCH_VMSGTU_VX, ARGS_VMSGTU_VX),
    ("vmsif.m", MATCH_VMSIF_M, ARGS_VMSIF_M),
    ("vmsle.vi", MATCH_VMSLE_VI, ARGS_VMSLE_VI),
    ("vmsle.vv", MATCH_VMSLE_VV, ARGS_VMSLE_VV),
    ("vmsle.vx", MATCH_VMSLE_VX, ARGS_VMSLE_VX),
    ("vmsleu.vi", MATCH_VMSLEU_VI, ARGS_VMSLEU_VI),
    ("vmsleu.vv", MATCH_VMSLEU_VV, ARGS_VMSLEU_VV),
    ("vmsleu.vx", MATCH_VMSLEU_VX, ARGS_VMSLEU_VX),
    ("vmslt.vv", MATCH_VMSLT_VV, ARGS_VMSLT_VV),
    ("vmslt.vx", MATCH_VMSLT_VX, ARGS_VMSLT_VX),
    ("vmsltu.vv", MATCH_VMSLTU_VV, ARGS_VMSLTU_VV),
    ("vmsltu.vx", MATCH_VMSLTU_VX, ARGS_VMSLTU_VX),
    ("vmsne.vi", MATCH_VMSNE_VI, ARGS_VMSNE_VI),
    ("vmsne.vv", MATCH_VMSNE_VV, ARGS_VMSNE_VV),
    ("vmsne.vx", MATCH_VMSNE_VX, ARGS_VMSNE_VX),
    ("vmsof.m", MATCH_VMSOF_M, ARGS_VMSOF_M),
    ("vmul.vv", MATCH_VMUL_VV, ARGS_VMUL_VV),
    ("vmul.vx", MATCH_VMUL_VX, ARGS_VMUL_VX),
    ("vmulh.vv", MATCH_VMULH_VV, ARGS_VMULH_VV),
    ("vmulh.vx", MATCH_VMULH_VX, ARGS_VMULH_VX),
    ("vmulhsu.vv", MATCH_VMULHSU_VV, ARGS_VMULHSU_VV),
    ("vmulhsu.vx", MATCH_VMULHSU_VX, ARGS_VMULHSU_VX),
    ("vmulhu.vv", MATCH_VMULHU_VV, ARGS_VMULHU_VV),
    ("vmulhu.vx", MATCH_VMULHU_VX, ARGS_VMULHU_VX),
    ("vmv1r.v", MATCH_VMV1R_V, ARGS_VMV1R_V),
    ("vmv2r.v", MATCH_VMV2R_V, ARGS_VMV2R_V),
    ("vmv4r.v", MATCH_VMV4R_V, ARGS_VMV4R_V),
    ("vmv8r.v", MATCH_VMV8R_V, ARGS_VMV8R_V),
    ("vmv.s.x", MATCH_VMV_S_X, ARGS_VMV_S_X),
    ("vmv.v.i", MATCH_VMV_V_I, ARGS_VMV_V_I),
    ("vmv.v.v", MATCH_VMV_V_V, ARGS_VMV_V_V),
    ("vmv.v.x", MATCH_VMV_V_X, ARGS_VMV_V_X),
    ("vmv.x.s", MATCH_VMV_X_S, ARGS_VMV_X_S),
    ("vmxnor.mm", MATCH_VMXNOR_MM, ARGS_VMXNOR_MM),
    ("vmxor.mm", MATCH_VMXOR_MM, ARGS_VMXOR_MM),
    ("vnclip.wi", MATCH_VNCLIP_WI, ARGS_VNCLIP_WI),
    ("vnclip.wv", MATCH_VNCLIP_WV, ARGS_VNCLIP_WV),
    ("vnclip.wx", MATCH_VNCLIP_WX, ARGS_VNCLIP_WX),
    ("vnclipu.wi", MATCH_VNCLIPU_WI, ARGS_VNCLIPU_WI),
    ("vnclipu.wv", MATCH_VNCLIPU_WV, ARGS_VNCLIPU_WV),
    ("vnclipu.wx", MATCH_VNCLIPU_WX, ARGS_VNCLIPU_WX),
    ("vnmsac.vv", MATCH_VNMSAC_VV, ARGS_VNMSAC_VV),
    ("vnmsac.vx", MATCH_VNMSAC_VX, ARGS_VNMSAC_VX),
    ("vnmsub.vv", MATCH_VNMSUB_VV, ARGS_VNMSUB_VV),
    ("vnmsub.vx", MATCH_VNMSUB_VX, ARGS_VNMSUB_VX),
    ("vnsra.wi", MATCH_VNSRA_WI, ARGS_VNSRA_WI),
    ("vnsra.wv", MATCH_VNSRA_WV, ARGS_VNSRA_WV),
    ("vnsra.wx", MATCH_VNSRA_WX, ARGS_VNSRA_WX),
    ("vnsrl.wi", MATCH_VNSRL_WI, ARGS_VNSRL_WI),
    ("vnsrl.wv", MATCH_VNSRL_WV, ARGS_VNSRL_WV),
    ("vnsrl.wx", MATCH_VNSRL_WX, ARGS_VNSRL_WX),
    ("vor.vi", MATCH_VOR_VI, ARGS_VOR_VI),
    ("vor.vv", MATCH_VOR_VV, ARGS_VOR_VV),
    ("vor.vx", MATCH_VOR_VX, ARGS_VOR_VX),
    ("vredand.vs", MATCH_VREDAND_VS, ARGS_VREDAND_VS),
    ("vredmax.vs", MATCH_VREDMAX_VS, ARGS_VREDMAX_VS),
    ("vredmaxu.vs", MATCH_VREDMAXU_VS, ARGS_VREDMAXU_VS),
    ("vredmin.vs", MATCH_VREDMIN_VS, ARGS_VREDMIN_VS),
    ("vredminu.vs", MATCH_VREDMINU_VS, ARGS_VREDMINU_VS),
    ("vredor.vs", MATCH_VREDOR_VS, ARGS_VREDOR_VS),
    ("vredsum.vs", MATCH_VREDSUM_VS, ARGS_VREDSUM_VS),
    ("vredxor.vs", MATCH_VREDXOR_VS, ARGS_VREDXOR_VS),
    ("vrem.vv", MATCH_VREM_VV, ARGS_VREM_VV),
    ("vrem.vx", MATCH_VREM_VX, ARGS_VREM_VX),
    ("vremu.vv", MATCH_VREMU_VV, ARGS_VREMU_VV),
    ("vremu.vx", MATCH_VREMU_VX, ARGS_VREMU_VX),
    ("vrgather.vi", MATCH_VRGATHER_VI, ARGS_VRGATHER_VI),
    ("vrgather.vv", MATCH_VRGATHER_VV, ARGS_VRGATHER_VV),
    ("vrgather.vx", MATCH_VRGATHER_VX, ARGS_VRGATHER_VX),
    (
        "vrgatherei16.vv",
        MATCH_VRGATHEREI16_VV,
        ARGS_VRGATHEREI16_VV,
    ),
    ("vrsub.vi", MATCH_VRSUB_VI, ARGS_VRSUB_VI),
    ("vrsub.vx", MATCH_VRSUB_VX, ARGS_VRSUB_VX),
    ("vs1r.v", MATCH_VS1R_V, ARGS_VS1R_V),
    ("vs2r.v", MATCH_VS2R_V, ARGS_VS2R_V),
    ("vs4r.v", MATCH_VS4R_V, ARGS_VS4R_V),
    ("vs8r.v", MATCH_VS8R_V, ARGS_VS8R_V),
    ("vsadd.vi", MATCH_VSADD_VI, ARGS_VSADD_VI),
    ("vsadd.vv", MATCH_VSADD_VV, ARGS_VSADD_VV),
    ("vsadd.vx", MATCH_VSADD_VX, ARGS_VSADD_VX),
    ("vsaddu.vi", MATCH_VSADDU_VI, ARGS_VSADDU_VI),
    ("vsaddu.vv", MATCH_VSADDU_VV, ARGS_VSADDU_VV),
    ("vsaddu.vx", MATCH_VSADDU_VX, ARGS_VSADDU_VX),
    ("vsbc.vvm", MATCH_VSBC_VVM, ARGS_VSBC_VVM),
    ("vsbc.vxm", MATCH_VSBC_VXM, ARGS_VSBC_VXM),
    ("vse1024.v", MATCH_VSE1024_V, ARGS_VSE1024_V),
    ("vse128.v", MATCH_VSE128_V, ARGS_VSE128_V),
    ("vse16.v", MATCH_VSE16_V, ARGS_VSE16_V),
    ("vse256.v", MATCH_VSE256_V, ARGS_VSE256_V),
    ("vse32.v", MATCH_VSE32_V, ARGS_VSE32_V),
    ("vse512.v", MATCH_VSE512_V, ARGS_VSE512_V),
    ("vse64.v", MATCH_VSE64_V, ARGS_VSE64_V),
    ("vse8.v", MATCH_VSE8_V, ARGS_VSE8_V),
    ("vsetivli", MATCH_VSETIVLI, ARGS_VSETIVLI),
    ("vsetvl", MATCH_VSETVL, ARGS_VSETVL),
    ("vsetvli", MATCH_VSETVLI, ARGS_VSETVLI),
    ("vsext.vf2", MATCH_VSEXT_VF2, ARGS_VSEXT_VF2),
    ("vsext.vf4", MATCH_VSEXT_VF4, ARGS_VSEXT_VF4),
    ("vsext.vf8", MATCH_VSEXT_VF8, ARGS_VSEXT_VF8),
    ("vslide1down.vx", MATCH_VSLIDE1DOWN_VX, ARGS_VSLIDE1DOWN_VX),
    ("vslide1up.vx", MATCH_VSLIDE1UP_VX, ARGS_VSLIDE1UP_VX),
    ("vslidedown.vi", MATCH_VSLIDEDOWN_VI, ARGS_VSLIDEDOWN_VI),
    ("vslidedown.vx", MATCH_VSLIDEDOWN_VX, ARGS_VSLIDEDOWN_VX),
    ("vslideup.vi", MATCH_VSLIDEUP_VI, ARGS_VSLIDEUP_VI),
    ("vslideup.vx", MATCH_VSLIDEUP_VX, ARGS_VSLIDEUP_VX),
    ("vsll.vi", MATCH_VSLL_VI, ARGS_VSLL_VI),
    ("vsll.vv", MATCH_VSLL_VV, ARGS_VSLL_VV),
    ("vsll.vx", MATCH_VSLL_VX, ARGS_VSLL_VX),
    ("vsm.v", MATCH_VSM_V, ARGS_VSM_V),
    ("vsmul.vv", MATCH_VSMUL_VV, ARGS_VSMUL_VV),
    ("vsmul.vx", MATCH_VSMUL_VX, ARGS_VSMUL_VX),
    ("vsoxei1024.v", MATCH_VSOXEI1024_V, ARGS_VSOXEI1024_V),
    ("vsoxei128.v", MATCH_VSOXEI128_V, ARGS_VSOXEI128_V),
    ("vsoxei16.v", MATCH_VSOXEI16_V, ARGS_VSOXEI16_V),
    ("vsoxei256.v", MATCH_VSOXEI256_V, ARGS_VSOXEI256_V),
    ("vsoxei32.v", MATCH_VSOXEI32_V, ARGS_VSOXEI32_V),
    ("vsoxei512.v", MATCH_VSOXEI512_V, ARGS_VSOXEI512_V),
    ("vsoxei64.v", MATCH_VSOXEI64_V, ARGS_VSOXEI64_V),
    ("vsoxei8.v", MATCH_VSOXEI8_V, ARGS_VSOXEI8_V),
    ("vsra.vi", MATCH_VSRA_VI, ARGS_VSRA_VI),
    ("vsra.vv", MATCH_VSRA_VV, ARGS_VSRA_VV),
    ("vsra.vx", MATCH_VSRA_VX, ARGS_VSRA_VX),
    ("vsrl.vi", MATCH_VSRL_VI, ARGS_VSRL_VI),
    ("vsrl.vv", MATCH_VSRL_VV, ARGS_VSRL_VV),
    ("vsrl.vx", MATCH_VSRL_VX, ARGS_VSRL_VX),
    ("vsse1024.v", MATCH_VSSE1024_V, ARGS_VSSE1024_V),
    ("vsse128.v", MATCH_VSSE128_V, ARGS_VSSE128_V),
    ("vsse16.v", MATCH_VSSE16_V, ARGS_VSSE16_V),
    ("vsse256.v", MATCH_VSSE256_V, ARGS_VSSE256_V),
    ("vsse32.v", MATCH_VSSE32_V, ARGS_VSSE32_V),
    ("vsse512.v", MATCH_VSSE512_V, ARGS_VSSE512_V),
    ("vsse64.v", MATCH_VSSE64_V, ARGS_VSSE64_V),
    ("vsse8.v", MATCH_VSSE8_V, ARGS_VSSE8_V),
    ("vssra.vi", MATCH_VSSRA_VI, ARGS_VSSRA_VI),
    ("vssra.vv", MATCH_VSSRA_VV, ARGS_VSSRA_VV),
    ("vssra.vx", MATCH_VSSRA_VX, ARGS_VSSRA_VX),
    ("vssrl.vi", MATCH_VSSRL_VI, ARGS_VSSRL_VI),
    ("vssrl.vv", MATCH_VSSRL_VV, ARGS_VSSRL_VV),
    ("vssrl.vx", MATCH_VSSRL_VX, ARGS_VSSRL_VX),
    ("vssub.vv", MATCH_VSSUB_VV, ARGS_VSSUB_VV),
    ("vssub.vx", MATCH_VSSUB_VX, ARGS_VSSUB_VX),
    ("vssubu.vv", MATCH_VSSUBU_VV, ARGS_VSSUBU_VV),
    ("vssubu.vx", MATCH_VSSUBU_VX, ARGS_VSSUBU_VX),
    ("vsub.vv", MATCH_VSUB_VV, ARGS_VSUB_VV),
    ("vsub.vx", MATCH_VSUB_VX, ARGS_VSUB_VX),
    ("vsuxei1024.v", MATCH_VSUXEI1024_V, ARGS_VSUXEI1024_V),
    ("vsuxei128.v", MATCH_VSUXEI128_V, ARGS_VSUXEI128_V),
    ("vsuxei16.v", MATCH_VSUXEI16_V, ARGS_VSUXEI16_V),
    ("vsuxei256.v", MATCH_VSUXEI256_V, ARGS_VSUXEI256_V),
    ("vsuxei32.v", MATCH_VSUXEI32_V, ARGS_VSUXEI32_V),
    ("vsuxei512.v", MATCH_VSUXEI512_V, ARGS_VSUXEI512_V),
    ("vsuxei64.v", MATCH_VSUXEI64_V, ARGS_VSUXEI64_V),
    ("vsuxei8.v", MATCH_VSUXEI8_V, ARGS_VSUXEI8_V),
    ("vwadd.vv", MATCH_VWADD_VV, ARGS_VWADD_VV),
    ("vwadd.vx", MATCH_VWADD_VX, ARGS_VWADD_VX),
    ("vwadd.wv", MATCH_VWADD_WV, ARGS_VWADD_WV),
    ("vwadd.wx", MATCH_VWADD_WX, ARGS_VWADD_WX),
    ("vwaddu.vv", MATCH_VWADDU_VV, ARGS_VWADDU_VV),
    ("vwaddu.vx", MATCH_VWADDU_VX, ARGS_VWADDU_VX),
    ("vwaddu.wv", MATCH_VWADDU_WV, ARGS_VWADDU_WV),
    ("vwaddu.wx", MATCH_VWADDU_WX, ARGS_VWADDU_WX),
    // isnt_name, base, args_cfg
    ("vwmacc.vv", MATCH_VWMACC_VV, ARGS_VWMACC_VV),
    ("vwmacc.vx", MATCH_VWMACC_VX, ARGS_VWMACC_VX),
    ("vwmaccsu.vv", MATCH_VWMACCSU_VV, ARGS_VWMACCSU_VV),
    ("vwmaccsu.vx", MATCH_VWMACCSU_VX, ARGS_VWMACCSU_VX),
    ("vwmaccu.vv", MATCH_VWMACCU_VV, ARGS_VWMACCU_VV),
    ("vwmaccu.vx", MATCH_VWMACCU_VX, ARGS_VWMACCU_VX),
    ("vwmaccus.vx", MATCH_VWMACCUS_VX, ARGS_VWMACCUS_VX),
    ("vwmul.vv", MATCH_VWMUL_VV, ARGS_VWMUL_VV),
    ("vwmul.vx", MATCH_VWMUL_VX, ARGS_VWMUL_VX),
    ("vwmulsu.vv", MATCH_VWMULSU_VV, ARGS_VWMULSU_VV),
    ("vwmulsu.vx", MATCH_VWMULSU_VX, ARGS_VWMULSU_VX),
    ("vwmulu.vv", MATCH_VWMULU_VV, ARGS_VWMULU_VV),
    ("vwmulu.vx", MATCH_VWMULU_VX, ARGS_VWMULU_VX),
    ("vwredsum.vs", MATCH_VWREDSUM_VS, ARGS_VWREDSUM_VS),
    ("vwredsumu.vs", MATCH_VWREDSUMU_VS, ARGS_VWREDSUMU_VS),
    ("vwsub.vv", MATCH_VWSUB_VV, ARGS_VWSUB_VV),
    ("vwsub.vx", MATCH_VWSUB_VX, ARGS_VWSUB_VX),
    ("vwsub.wv", MATCH_VWSUB_WV, ARGS_VWSUB_WV),
    ("vwsub.wx", MATCH_VWSUB_WX, ARGS_VWSUB_WX),
    ("vwsubu.vv", MATCH_VWSUBU_VV, ARGS_VWSUBU_VV),
    ("vwsubu.vx", MATCH_VWSUBU_VX, ARGS_VWSUBU_VX),
    ("vwsubu.wv", MATCH_VWSUBU_WV, ARGS_VWSUBU_WV),
    ("vwsubu.wx", MATCH_VWSUBU_WX, ARGS_VWSUBU_WX),
    ("vxor.vi", MATCH_VXOR_VI, ARGS_VXOR_VI),
    ("vxor.vv", MATCH_VXOR_VV, ARGS_VXOR_VV),
    ("vxor.vx", MATCH_VXOR_VX, ARGS_VXOR_VX),
    ("vzext.vf2", MATCH_VZEXT_VF2, ARGS_VZEXT_VF2),
    ("vzext.vf4", MATCH_VZEXT_VF4, ARGS_VZEXT_VF4),
    ("vzext.vf8", MATCH_VZEXT_VF8, ARGS_VZEXT_VF8),
];
"""

# Extract first element of each tuple
first_elements = [line.strip().split(",")[0].strip('(")') 
                  for line in code.strip().splitlines() if line.strip()]

# Print formatted list with line breaks every 8 elements
print("[")
for i in range(0, len(first_elements), 8):
    chunk = first_elements[i:i+8]
    print("    " + ", ".join(f'"{x}"' for x in chunk) + ",")
print("]")
